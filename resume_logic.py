import logging
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
import os

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

def compare_resume(resume_text, job_description):
    """
    Compares the given resume and job description using OpenAI's GPT-based model.

    :param resume_text: The text content of the resume.
    :param job_description: The text content of the job description.
    :return: A structured dictionary containing the analysis results.
    """
    try:
        logger.info("Starting comparison between resume and job description.")

        # Ensure API key is loaded
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            logger.error("OpenAI API key is missing.")
            raise ValueError("OpenAI API key is missing. Please set it in the environment variables.")

        # Validate inputs
        if not resume_text or not job_description:
            logger.error("Resume text or job description is empty.")
            raise ValueError("Resume text and job description cannot be empty.")

        logger.info("Initializing OpenAI model (GPT-4o mini)...")
        # Initialize ChatOpenAI
        llm = ChatOpenAI(model="GPT-4o mini", api_key=api_key, request_timeout=30)

        # Define the prompt template
        logger.info("Creating prompt template for resume analysis.")
        template = """
        Compare the given RESUME and JOB DESCRIPTION. Provide:
        - A compatibility score (0-100).
        - Key strengths of the resume.
        - Areas for improvement.

        RESUME:
        {resume}

        JOB DESCRIPTION:
        {job_description}
        """
        prompt = PromptTemplate(input_variables=["resume", "job_description"], template=template)

        # Run the LLM chain
        logger.info("Sending data to the LLM for analysis.")
        chain = LLMChain(llm=llm, prompt=prompt)
        result = chain.run({"resume": resume_text, "job_description": job_description})

        if not result:
            logger.warning("No analysis generated by the LLM.")
            return {"error": "No analysis generated by the model."}

        logger.info("Received analysis results from LLM.")
        return {"analysis": result}
    except Exception as e:
        logger.exception("Error during resume analysis.")
        raise ValueError(f"Analysis failed: {e}")
